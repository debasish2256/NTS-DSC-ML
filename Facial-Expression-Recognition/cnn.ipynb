{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c97cf2063956>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#from cnn_utils import *\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from cnn_utils import *\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-dd26627d88ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Python36(64bit)/programs/intern/fer2013.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('C:/Python36(64bit)/programs/intern/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d2907a6b0b04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Usage'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df1=df[:6500]\n",
    "    \n",
    "df2=df1.drop('Usage',axis=1)\n",
    "\n",
    "train=df2[:6000]\n",
    "test= df2[6000:6500]\n",
    "train_x=train.drop('emotion',axis=1)\n",
    "#train_y=train['emotion']\n",
    "test_x=test.drop('emotion',axis=1)\n",
    "train_y=train.drop('pixels',axis=1)\n",
    "#test_y=test['emotion']\n",
    "train_x= train_x['pixels'].str.split(' ',expand=True) \n",
    "train_x=train_x.astype('float')\n",
    "test_x= test_x['pixels'].str.split(' ',expand=True) \n",
    "test_x=test_x.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 6000\n",
      "number of test examples = 500\n",
      "X_train shape: (6000, 48, 48, 1)\n",
      "Y_train shape: (6000, 7)\n",
      "X_test shape: (500, 48, 48, 1)\n",
      "Y_test shape: (500, 7)\n"
     ]
    }
   ],
   "source": [
    "test_y=test.drop('pixels',axis=1)\n",
    "Y_test1=test_y\n",
    "train_x1=train_x\n",
    "test_x1=test_x\n",
    "Y_train1=train_y\n",
    "\n",
    "X_train1=train_x1.values\n",
    "X_test1=test_x1.values\n",
    "\n",
    "X_train2=X_train1/255\n",
    "X_test2=X_test1/255\n",
    "\n",
    "Y_test2=Y_test1.values\n",
    "Y_train2=Y_train1.values\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "Y_train3 = convert_to_one_hot(Y_train2, 7)\n",
    "Y_test3 = convert_to_one_hot(Y_test2, 7)\n",
    "Y_train=Y_train3.T\n",
    "Y_test=Y_test3.T\n",
    "\n",
    "##reshape\n",
    "X_train=X_train2.reshape(X_train2.shape[0],48,48,1)\n",
    "X_test=X_test2.reshape(X_test2.shape[0],48,48,1)\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ2 lines)\n",
    "    X = tf.placeholder(tf.float32, shape= [None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, shape =[None, n_y])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [4, 4, 1, 8]\n",
    "                        W2 : [2, 2, 8, 16]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 2 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", shape=[4, 4, 1, 8], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\", shape=[2,2,8,16], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "     # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    print(A1.shape)\n",
    "    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1, 8, 8, 1], strides = [1, 8, 8, 1], padding='SAME')\n",
    "    print(P1.shape)\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    print(A2.shape)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1, 4, 4, 1], strides = [1, 4, 4, 1], padding='SAME')\n",
    "    # FLATTEN\n",
    "    print(P2.shape)\n",
    "    P = tf.contrib.layers.flatten(P2)\n",
    "    print(P.shape)\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 7 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z3 = tf.contrib.layers.fully_connected(P, 7, activation_fn=None)\n",
    "    print(Z3.shape)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "\n",
    "    return Z3\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost =   cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
    "          num_epochs = 100, minibatch_size = 64, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_train -- test set, of shape (None, n_y = 6)\n",
    "    X_test -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_test -- test set, of shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "        \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 10 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        fig = plt.figure()\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        fig.savefig(\"graph.png\")\n",
    "     \n",
    "\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.839861\n",
      "Cost after epoch 10: 1.626417\n",
      "Cost after epoch 20: 1.530100\n",
      "Cost after epoch 30: 1.499774\n",
      "Cost after epoch 40: 1.466964\n",
      "Cost after epoch 50: 1.455192\n",
      "Cost after epoch 60: 1.447458\n",
      "Cost after epoch 70: 1.445986\n",
      "Cost after epoch 80: 1.445656\n",
      "Cost after epoch 90: 1.440252\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbe93520940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.4595\n",
      "Test Accuracy: 0.42\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"C:/Python36(64bit)/programs/intern/karan.jpg\"\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(48,48))\n",
    "#plt.imshow(my_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    #b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    #b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    #W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    #b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              #\"b1\": b1,\n",
    "              \"W2\": W2}\n",
    "              #\"b2\": b2,\n",
    "              #\"W3\": W3,\n",
    "              #\"b3\": b3}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [1,48,48,1])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict(x, parameters)\n",
    "    p = tf.argmax(z3)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#my_image_prediction = predict(my_image, parameters)\n",
    "#print(\"Your algorithm predicts: y = \" + str(np.squeeze(my_image_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
