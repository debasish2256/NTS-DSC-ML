{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from numpy import genfromtxt, array\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Step Gradient Descent function => use the error/ cost function and then minimize it using partial deriviatives\n",
    "def step_gradient(b_current, m_current, points, learningRate, iteration):\n",
    "\t\n",
    "\tb_gradient = 0\n",
    "\tm_gradient = 0\n",
    "\tN = float(len(points))\n",
    "\t\n",
    "\tfor i in range(len(points)):\n",
    "\t\tx = points[i,0]\n",
    "\t\ty = points[i,1]\n",
    "\t\t#  Partial derivatives calcultion for b_gradient an m_gradient for error funcion f(X)= ((y_initial-y_predicted)^2) / N\n",
    "\n",
    "\t\t# (d)/(db)((y - (m x + b))^2/N) = (2 (b + m x - y))/N = - (2/N (-b -mx +y)) =  - (2/N (y - (mx+b))\n",
    "\t\tb_gradient += - (2/N) * (y - ((m_current * x) + b_current))\n",
    "\n",
    "\t\t# (d)/(db)((y - (m x + b))^2/N) = (2x (b + m x - y))/N = - (2x/N (-b -mx +y)) = - (2x/N (y - (mx+b))\n",
    "\t\tm_gradient += - (2/N) * x * (y - ((m_current * x) + b_current))\n",
    "\n",
    "\t\t# print \"At row = {0}, b_gradient = {1}, m_gradient = {2}\".format(i, b_gradient, m_gradient)\n",
    "\n",
    "\tnew_b = b_current - (learningRate * b_gradient)\n",
    "\tnew_m = m_current - (learningRate * m_gradient)\n",
    "\t# print \"\\n After {0} iterations the new b = b_current - (learningRate * b_gradient) = {1} - ({3} * {2}) = {4}\".format(iteration+1, b_current, b_gradient, learningRate, new_b)\n",
    "\t# print \"After {0} iterations the new m = m_current - (learningRate * m_gradient) = {1} - ({3} * {2}) = {4} \\n\".format(iteration+1, m_current, m_gradient, learningRate, new_m)\n",
    "\n",
    "\n",
    "\treturn [new_b, new_m]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_runner(points, starting_b, starting_m, learning_rate, num_iterations):\n",
    "\t\n",
    "\tb1 = starting_b\n",
    "\tm1 = starting_m\n",
    "\tfor i in range(num_iterations):\n",
    "\t\tb1, m1 = step_gradient(b1, m1, array(points), learning_rate, i)\n",
    "\t\n",
    "\treturn [b1, m1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Square of Error function\n",
    "def compute_error_for_line_given_points(b, m, points):\n",
    "\t\n",
    "\ttotalError = 0\n",
    "\terror = 0\n",
    "\t\n",
    "\tfor i in range(0, len(points)):\n",
    "\t\tx = points[i,0]\n",
    "\t\ty = points[i,1]\n",
    "\t\t# Our Error funcion f(x) = ((y_initial - y_predicted)^2) / Number of data rows\n",
    "\t\terror = ((y - (m*x + b)) ** 2) / len(points)\n",
    "\t\ttotalError += error / len(points)\n",
    "#\t\tprint (\"At Row \",i,\" using b = \",b,\" and m = \",m,\" Error = \",error)\n",
    "\n",
    "\tprint (\"\\n Total Error is: \",totalError)\n",
    "\treturn error, totalError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " First compute Error for each row by using equation y_predicted = mx +b and error =  (y - y_predicted) ^2 / len(points) by using random b = {0}, and m = {1} \n",
      "\n",
      "1 1\n",
      "\n",
      " Total Error is:  1.12048022748\n",
      "\n",
      " Now, let's run gradient_descent_runner to get new m and b with learning rate of :  0.001  and  100  iterations \n",
      "\n",
      " Total Error is:  0.0103489501919\n",
      "\n",
      "By using gradient_descent_runner after  100  iterations final b = 0.983145951682  and final m = 4.72793122183\n",
      "\n",
      " Enter BMI to get Blood Sugar\n",
      "\n",
      "\n",
      " Test/Sample BMI is: \n",
      " 20\n",
      "\n",
      " Blood Sugar predicted is : \n",
      " 95.5417703883\n"
     ]
    }
   ],
   "source": [
    "def linear_regression_model():\n",
    "\n",
    "\t#data from data.csv cotaining number of study hours and GPA\n",
    "\tpoints = genfromtxt(\"diabetes.csv\", delimiter=\",\")\n",
    "\t\n",
    "\t# choose learning rate\n",
    "\tlearning_rate = 0.001\n",
    "\t\n",
    "\t# iniital y-intercept guess aka the constant in linear equation\n",
    "\tinitial_b = 1\n",
    "\t\n",
    "\t#  iniital slope guess\n",
    "\tinitial_m = 1\n",
    "\t\n",
    "\t# choose numbr of iterations to run linear regression\n",
    "\tnum_iterations = 100\n",
    "\t\n",
    "\t#print linear regression is working\n",
    "\tprint (\"\\n First compute Error for each row by using equation y_predicted = mx +b and error =  (y - y_predicted) ^2 / len(points) by using random b = {0}, and m = {1} \\n\")\n",
    "\tprint(initial_b, initial_m)\n",
    "\n",
    "\t# compute errors\n",
    "\tcompute_error_for_line_given_points(initial_b, initial_m,points)\n",
    "\t\n",
    "\tprint (\"\\n Now, let's run gradient_descent_runner to get new m and b with learning rate of : \",learning_rate,\" and \",num_iterations,\" iterations \")\n",
    "\t\n",
    "\t[b,m] = gradient_descent_runner(points, initial_b, initial_m, learning_rate, num_iterations)\n",
    "\n",
    "\t# print (b,m)\n",
    "\n",
    "# \t# compute final error with new b and m calculated from gradient_descent_runner\n",
    "\n",
    "\tcompute_error_for_line_given_points(b,m,points)\n",
    "\n",
    "\tprint (\"\\nBy using gradient_descent_runner after \",num_iterations,\" iterations final b =\",b,\" and final m =\",m)\n",
    "\treturn b,m\n",
    "\n",
    "# as usual start with main function and put it in the end of the code\n",
    "if __name__ == '__main__':\n",
    "\tglobal b\n",
    "\tglobal m\n",
    "\tb,m=linear_regression_model()\n",
    "\t\n",
    "# now lets use this new b and m to predict some random person expected life expectancy by given BMI\n",
    "#b,m=linear_regression_model()\n",
    "print (\"\\n Enter BMI to get Blood Sugar\\n\")\n",
    "X_test = 20\n",
    "print (\"\\n Test/Sample BMI is: \\n\",X_test)\n",
    "y_test = m * X_test + b\n",
    "print (\"\\n Blood Sugar predicted is : \\n\",y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
